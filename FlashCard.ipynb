{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1AG3cyjLFPA",
        "outputId": "0093363d-883b-4b44-cddd-88da767e57e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai SQLAlchemy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJhu69Y-LSox",
        "outputId": "da27df1d-53a4-46e6-aa08-d95321a1260b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy) (3.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "OPENAI_API_KEY = userdata.get('OPENAI')"
      ],
      "metadata": {
        "id": "MI7feQ8sMi06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "i6cdrBYeNy1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from sqlalchemy import (\n",
        "    create_engine, Column, Integer, String, Text\n",
        ")\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import re\n",
        "\n",
        "def extract_json_from_response(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Given a ChatGPT response that contains a ```json ... ``` block,\n",
        "    finds the first JSON object inside and returns it as a Python dict.\n",
        "    \"\"\"\n",
        "    # This will match ```json { ... } ```\n",
        "    pattern = r\"```json\\s*(\\{.*?\\})\\s*```\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if not match:\n",
        "        return json.loads(text)\n",
        "    json_str = match.group(1)\n",
        "    return json.loads(json_str)\n",
        "\n",
        "# ── 1. Configure OpenAI ───────────────────────────────────────────────────────\n",
        "def fetch_ai_data(term: str,client) -> dict:\n",
        "    prompt = f\"\"\"\n",
        "You are an excellent English Speaker. Given the input term: «{term}», do the following:\n",
        "1) Detect if it's a single word or a multi-word phrase.\n",
        "2) If it's a phrase, classify it as either:\n",
        "   - include a phrasal verb (then extract the verb part into \"verb\"), or\n",
        "   - an idiom (set \"verb\" to null).\n",
        "3) Produce:\n",
        "   • \"meaning\": a one-sentence definition.\n",
        "   • \"examples\": one example sentences.\n",
        "   • \"alternatives\": (if phrase) an array of two alternative phrasings. (if word) an array of two synonyms.\n",
        "\n",
        "Return JSON file exactly in this content:\n",
        "  \"type\": \"word\" | \"phrase\",\n",
        "  \"verb\": string|null,\n",
        "  \"meaning\": string,\n",
        "  \"examples\": string,\n",
        "  \"alternatives\": string, string\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return extract_json_from_response(response.choices[0].message.content)\n",
        "\n",
        "# ── 2. Define our SQL schema via SQLAlchemy ──────────────────────────────────\n",
        "Base = declarative_base()\n",
        "\n",
        "class Word(Base):\n",
        "    __tablename__ = 'word'\n",
        "    id      = Column(Integer, primary_key=True, autoincrement=True)\n",
        "    word    = Column(String, nullable=False, unique=True)\n",
        "    meaning = Column(Text,   nullable=False)\n",
        "    examples    = Column(Text,   nullable=False)\n",
        "    alternatives = Column(Text,   nullable=False)  # we'll JSON‐dump\n",
        "\n",
        "class Phrase(Base):\n",
        "    __tablename__ = 'phrase'\n",
        "    id          = Column(Integer, primary_key=True, autoincrement=True)\n",
        "    phrase      = Column(String, nullable=False) # unique=False because we want to allow same phrases with different meanings\n",
        "    verb        = Column(String, nullable=True)\n",
        "    meaning     = Column(Text,   nullable=False)\n",
        "    examples    = Column(Text,   nullable=False)\n",
        "    alternatives = Column(Text,   nullable=False)  # JSON‐dump\n",
        "\n",
        "db_path = '/content/drive/MyDrive/Colab Notebooks/flashcards.db'\n",
        "engine = create_engine(f'sqlite:///{db_path}')\n",
        "Session = sessionmaker(bind=engine)\n",
        "if not os.path.exists(db_path):\n",
        "    Base.metadata.create_all(engine)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS6wOeDtO4cO",
        "outputId": "f771750f-f1e3-40eb-b773-7dd2948b6684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-b7a8e2d4c231>:56: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "con = sqlite3.connect(db_path)\n",
        "cur = con.cursor()\n",
        "res = cur.execute(\"PRAGMA table_info(phrase);\")\n",
        "print(res.fetchall())\n",
        "con.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVuKp4VHhr2m",
        "outputId": "ccc155f8-b614-4e45-97fb-2e7f46a9df14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'id', 'INTEGER', 1, None, 1), (1, 'phrase', 'VARCHAR', 1, None, 0), (2, 'verb', 'VARCHAR', 0, None, 0), (3, 'meaning', 'TEXT', 1, None, 0), (4, 'examples', 'TEXT', 1, None, 0), (5, 'alternatives', 'TEXT', 1, None, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# ── 3. Read CSV → AI → DB ────────────────────────────────────────────────────\n",
        "def process_csv(path):\n",
        "    session = Session()\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    worksheet = gc.open(path).sheet1\n",
        "\n",
        "    # get_all_values gives a list of rows.\n",
        "    rows = worksheet.get_all_values()\n",
        "    for row in rows:\n",
        "        term = row[0].strip()\n",
        "        if not term:\n",
        "            continue\n",
        "\n",
        "        if len(row) == 2 and row[1] == '1':\n",
        "            print(f\"Term '{term}' already stored, skipping.\")\n",
        "            continue\n",
        "\n",
        "        data = fetch_ai_data(term,client)\n",
        "        if data[\"type\"] == \"word\":\n",
        "            w = Word(\n",
        "                word    = term,\n",
        "                meaning = data[\"meaning\"],\n",
        "                examples = data[\"examples\"],\n",
        "                alternatives = json.dumps(data[\"alternatives\"], ensure_ascii=False)\n",
        "            )\n",
        "            session.merge(w)\n",
        "            print(f\"Term '{term}' Added to Word\")\n",
        "\n",
        "        else:\n",
        "            p = Phrase(\n",
        "                phrase      = term,\n",
        "                verb        = data[\"verb\"],  # or None\n",
        "                meaning     = data[\"meaning\"],\n",
        "                examples    = data[\"examples\"],\n",
        "                alternatives = json.dumps(data[\"alternatives\"], ensure_ascii=False)\n",
        "            )\n",
        "            session.merge(p)\n",
        "            print(f\"Term '{term}' Added to Phrase\")\n",
        "        row[1] = '1'\n",
        "    session.commit()\n",
        "\n",
        "    cell_list = worksheet.range(f'B1:B{len(rows)}')\n",
        "\n",
        "    for idx, cell in enumerate(cell_list):\n",
        "      cell.value = rows[idx][1]\n",
        "\n",
        "    worksheet.update_cells(cell_list)\n",
        "\n",
        "    session.close()\n",
        "    print(\"All terms processed and stored into SQL.\")\n",
        "\n",
        "\n",
        "process_csv('FlashCardApp')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5CzfWwCLQSf",
        "outputId": "07d82fa3-ea63-4d0a-b9d8-bc8f2d1e547c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term 'Knock them dead' Added to Phrase\n",
            "Term 'Evidently' Added to Word\n",
            "Term 'That explains it' Added to Phrase\n",
            "Term 'Insist' Added to Word\n",
            "Term 'In the first place' Added to Phrase\n",
            "Term 'As evidenced by my experiecence of' Added to Phrase\n",
            "Term 'Go down the tube' Added to Phrase\n",
            "Term 'as a matter of fact' Added to Phrase\n",
            "Term 'The ball is in your court' Added to Phrase\n",
            "Term 'knock yourself out' Added to Phrase\n",
            "Term 'That's not the point' Added to Phrase\n",
            "Term 'Look so blue' Added to Phrase\n",
            "Term 'That says it all' Added to Phrase\n",
            "Term 'Put it there' Added to Phrase\n",
            "Term 'Swamped' Added to Word\n",
            "Term 'Back off' Added to Phrase\n",
            "Term 'Put my ass on the line' Added to Phrase\n",
            "Term 'Pity' Added to Word\n",
            "Term 'Self assured' Added to Phrase\n",
            "Term 'keep your eye on' Added to Phrase\n",
            "Term 'Have the ball' Added to Phrase\n",
            "Term 'Just so you know' Added to Phrase\n",
            "Term 'Set my sight on' Added to Phrase\n",
            "Term 'Kick someone's ass' Added to Phrase\n",
            "Term 'Push on me' Added to Phrase\n",
            "Term 'As I recall / Which I recall' Added to Phrase\n",
            "Term 'Hold out on' Added to Phrase\n",
            "All terms processed and stored into SQL.\n"
          ]
        }
      ]
    }
  ]
}